{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-11T19:34:15.298701Z",
     "iopub.status.busy": "2024-08-11T19:34:15.298095Z",
     "iopub.status.idle": "2024-08-11T20:32:09.064461Z",
     "shell.execute_reply": "2024-08-11T20:32:09.063428Z",
     "shell.execute_reply.started": "2024-08-11T19:34:15.298657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/3067349589.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].replace(missing_value_placeholders, np.nan, inplace=True)\n",
      "/tmp/ipykernel_34/3067349589.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode().iloc[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'id' 열에는 결측치가 없습니다.\n",
      "'gender' 열에는 결측치가 없습니다.\n",
      "'masterCategory' 열에는 결측치가 없습니다.\n",
      "'subCategory' 열에는 결측치가 없습니다.\n",
      "'articleType' 열에는 결측치가 없습니다.\n",
      "'baseColour' 열에는 결측치가 없습니다.\n",
      "'season' 열에는 결측치가 없습니다.\n",
      "'year' 열에는 결측치가 없습니다.\n",
      "'usage' 열에는 결측치가 없습니다.\n",
      "'productDisplayName' 열에는 결측치가 없습니다.\n",
      "다음 ID는 이미지가 없습니다: {'39410', '39401', '39425', '12347', '39403'}\n",
      "data-preprocessing end..\n",
      "\n",
      "data-loader end..\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 141MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Training..\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/3067349589.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  return torch.tensor(embedded_vectors, dtype=torch.float32).to(device)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 71.0928, Validation F1 Score: 0.8902, Validation gender F1 Score: 0.9729, Validation article F1 Score: 0.8748, Validation season F1 Score: 0.7922, Validation usage_metrics F1 Score: 0.9208, Validation Acc Score: 0.8949, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 39.8058, Validation F1 Score: 0.9121, Validation gender F1 Score: 0.9812, Validation article F1 Score: 0.9168, Validation season F1 Score: 0.8248, Validation usage_metrics F1 Score: 0.9257, Validation Acc Score: 0.9153, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 33.0062, Validation F1 Score: 0.9216, Validation gender F1 Score: 0.9842, Validation article F1 Score: 0.9338, Validation season F1 Score: 0.8352, Validation usage_metrics F1 Score: 0.9333, Validation Acc Score: 0.9235, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 29.0433, Validation F1 Score: 0.9261, Validation gender F1 Score: 0.9868, Validation article F1 Score: 0.9393, Validation season F1 Score: 0.8407, Validation usage_metrics F1 Score: 0.9377, Validation Acc Score: 0.9277, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 26.1772, Validation F1 Score: 0.9277, Validation gender F1 Score: 0.9863, Validation article F1 Score: 0.9423, Validation season F1 Score: 0.8447, Validation usage_metrics F1 Score: 0.9376, Validation Acc Score: 0.9297, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 24.2056, Validation F1 Score: 0.9326, Validation gender F1 Score: 0.9867, Validation article F1 Score: 0.9494, Validation season F1 Score: 0.8582, Validation usage_metrics F1 Score: 0.9362, Validation Acc Score: 0.9340, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 22.2089, Validation F1 Score: 0.9328, Validation gender F1 Score: 0.9882, Validation article F1 Score: 0.9485, Validation season F1 Score: 0.8535, Validation usage_metrics F1 Score: 0.9408, Validation Acc Score: 0.9346, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 20.3868, Validation F1 Score: 0.9369, Validation gender F1 Score: 0.9933, Validation article F1 Score: 0.9544, Validation season F1 Score: 0.8558, Validation usage_metrics F1 Score: 0.9440, Validation Acc Score: 0.9378, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 18.7544, Validation F1 Score: 0.9385, Validation gender F1 Score: 0.9909, Validation article F1 Score: 0.9574, Validation season F1 Score: 0.8581, Validation usage_metrics F1 Score: 0.9477, Validation Acc Score: 0.9402, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 17.2972, Validation F1 Score: 0.9400, Validation gender F1 Score: 0.9926, Validation article F1 Score: 0.9582, Validation season F1 Score: 0.8660, Validation usage_metrics F1 Score: 0.9433, Validation Acc Score: 0.9411, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 16.0754, Validation F1 Score: 0.9401, Validation gender F1 Score: 0.9930, Validation article F1 Score: 0.9593, Validation season F1 Score: 0.8672, Validation usage_metrics F1 Score: 0.9408, Validation Acc Score: 0.9412, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 14.5899, Validation F1 Score: 0.9357, Validation gender F1 Score: 0.9933, Validation article F1 Score: 0.9542, Validation season F1 Score: 0.8532, Validation usage_metrics F1 Score: 0.9420, Validation Acc Score: 0.9362, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 13.5002, Validation F1 Score: 0.9367, Validation gender F1 Score: 0.9920, Validation article F1 Score: 0.9575, Validation season F1 Score: 0.8548, Validation usage_metrics F1 Score: 0.9426, Validation Acc Score: 0.9380, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 12.2391, Validation F1 Score: 0.9363, Validation gender F1 Score: 0.9904, Validation article F1 Score: 0.9556, Validation season F1 Score: 0.8552, Validation usage_metrics F1 Score: 0.9439, Validation Acc Score: 0.9369, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 11.4764, Validation F1 Score: 0.9423, Validation gender F1 Score: 0.9915, Validation article F1 Score: 0.9612, Validation season F1 Score: 0.8686, Validation usage_metrics F1 Score: 0.9478, Validation Acc Score: 0.9432, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 10.7368, Validation F1 Score: 0.9393, Validation gender F1 Score: 0.9927, Validation article F1 Score: 0.9628, Validation season F1 Score: 0.8591, Validation usage_metrics F1 Score: 0.9424, Validation Acc Score: 0.9402, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 9.8728, Validation F1 Score: 0.9398, Validation gender F1 Score: 0.9944, Validation article F1 Score: 0.9593, Validation season F1 Score: 0.8612, Validation usage_metrics F1 Score: 0.9442, Validation Acc Score: 0.9409, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 9.5188, Validation F1 Score: 0.9366, Validation gender F1 Score: 0.9934, Validation article F1 Score: 0.9615, Validation season F1 Score: 0.8465, Validation usage_metrics F1 Score: 0.9450, Validation Acc Score: 0.9372, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 8.8324, Validation F1 Score: 0.9357, Validation gender F1 Score: 0.9940, Validation article F1 Score: 0.9613, Validation season F1 Score: 0.8393, Validation usage_metrics F1 Score: 0.9484, Validation Acc Score: 0.9362, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 8.2563, Validation F1 Score: 0.9400, Validation gender F1 Score: 0.9942, Validation article F1 Score: 0.9593, Validation season F1 Score: 0.8613, Validation usage_metrics F1 Score: 0.9454, Validation Acc Score: 0.9409, \n",
      "Training completed\n",
      "\n",
      "Test start..\n",
      "\n",
      "Epoch [15/20], Test F1 Score: 0.9442, Test gender F1 Score: 0.9921, Test article F1 Score: 0.9674, Test season F1 Score: 0.8694, Test usage_metrics F1 Score: 0.9480, Test Acc Score: 0.9450, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "root_dir = \"/kaggle/working/\"\n",
    "root_imageset_dir = \"/kaggle/input/fashion-product-images-small/images\"\n",
    "\n",
    "now = datetime.now(timezone('Asia/Seoul'))\n",
    "folder_name = now.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "root_work_dir = os.path.join(root_dir, folder_name)\n",
    "os.mkdir(root_work_dir)\n",
    "root_work_weight_dir = os.path.join(root_work_dir, \"weights\")\n",
    "os.mkdir(root_work_weight_dir)\n",
    "\n",
    "y_columns = ['gender', 'articleType', 'season', 'usage']\n",
    "x_columns = ['masterCategory', 'subCategory', 'baseColour', 'year', 'productDisplayName']\n",
    "# Load the data\n",
    "data = pd.read_csv('/kaggle/input/fashion-product-images-small/styles.csv', on_bad_lines='skip')\n",
    "\n",
    "# Define common placeholders for missing values\n",
    "missing_value_placeholders = ['', ' ', '-', 'None', 'NA', 'N/A', 'null']\n",
    "\n",
    "# Convert all placeholders to NaN\n",
    "for column in y_columns + x_columns:\n",
    "    data[column].replace(missing_value_placeholders, np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values - Ensure no NaNs\n",
    "for column in y_columns + x_columns:\n",
    "    if data[column].isnull().sum() > 0:  # Check if there are any NaNs\n",
    "        data[column].fillna(data[column].mode().iloc[0], inplace=True)\n",
    "\n",
    "# Label encoding for categorical features\n",
    "label_encoders = {}\n",
    "for column in y_columns + x_columns[:-1]:  # Skip productDisplayName\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Check for missing values in each column\n",
    "for column in data.columns:\n",
    "    missing_indices = data[data[column].isnull()].index.tolist()\n",
    "    if missing_indices:\n",
    "        print(f\"'{column}' 열의 결측치가 있습니다: {missing_indices}\")\n",
    "    else:\n",
    "        print(f\"'{column}' 열에는 결측치가 없습니다.\")\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = os.listdir(root_imageset_dir)\n",
    "image_files = [f for f in image_files if f.endswith('.jpg')]\n",
    "\n",
    "# Extract IDs from image filenames\n",
    "image_ids = {os.path.splitext(f)[0] for f in image_files}\n",
    "\n",
    "# Get the IDs from the DataFrame\n",
    "data_ids = set(data['id'].astype(str))\n",
    "\n",
    "# Find IDs in data that do not have corresponding images\n",
    "missing_image_ids = data_ids - image_ids\n",
    "if missing_image_ids:\n",
    "    print(f\"다음 ID는 이미지가 없습니다: {missing_image_ids}\")\n",
    "\n",
    "# Filter the DataFrame to only include rows with available images\n",
    "data = data[data['id'].astype(str).isin(image_ids)].reset_index(drop=True)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    data[['id'] + x_columns], \n",
    "    data[y_columns], \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, \n",
    "    y_temp, \n",
    "    test_size=0.5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"data-preprocessing end..\\n\")\n",
    "\n",
    "# Load Word2Vec embeddings\n",
    "word2vec_path = '/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin'  # Word2Vec 모델 경로\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to embed product display name using Word2Vec\n",
    "def embed_product_display_name(product_display_names):\n",
    "    embedded_vectors = []\n",
    "    for name in product_display_names:\n",
    "        words = name.split()\n",
    "        word_vectors = [word2vec[word] for word in words if word in word2vec]\n",
    "        if word_vectors:\n",
    "            embedded_vectors.append(np.mean(word_vectors, axis=0))\n",
    "        else:\n",
    "            embedded_vectors.append(np.zeros(300))  # Word2Vec 벡터 차원\n",
    "    return torch.tensor(embedded_vectors, dtype=torch.float32).to(device)\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, X, y, root_dir, transform=None):\n",
    "        self.X = X.reset_index(drop=True)  # Reset index to ensure consistency\n",
    "        self.y = y.reset_index(drop=True)  # Reset index to ensure consistency\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.X.iloc[idx]['id']) + '.jpg')\n",
    "        image = Image.open(img_name).convert('RGB')  # Ensure image is RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Access the label using the correct column structure\n",
    "        gender_idx = int(self.y.iloc[idx, 0])  # Adjust indexing to single integer\n",
    "        article_idx = int(self.y.iloc[idx, 1])\n",
    "        season_idx = int(self.y.iloc[idx, 2])\n",
    "        usage_idx = int(self.y.iloc[idx, 3])\n",
    "\n",
    "        # Encode additional features\n",
    "        master_category_idx = float(self.X.iloc[idx]['masterCategory'])\n",
    "        sub_category_idx = float(self.X.iloc[idx]['subCategory'])\n",
    "        base_colour_idx = float(self.X.iloc[idx]['baseColour'])\n",
    "        year = float(self.X.iloc[idx]['year'])\n",
    "\n",
    "        # Get the text embedding\n",
    "        product_display_name_embedding = embed_product_display_name([self.X.iloc[idx]['productDisplayName']])\n",
    "\n",
    "        # Convert labels to one-hot encoded vectors\n",
    "        gender_one_hot = np.eye(num_gender)[gender_idx]\n",
    "        article_one_hot = np.eye(num_article)[article_idx]\n",
    "        season_one_hot = np.eye(num_season)[season_idx]\n",
    "        usage_one_hot = np.eye(num_usage)[usage_idx]\n",
    "\n",
    "        labels = {\n",
    "            'gender': torch.tensor(gender_one_hot, dtype=torch.float),\n",
    "            'articleType': torch.tensor(article_one_hot, dtype=torch.float),\n",
    "            'season': torch.tensor(season_one_hot, dtype=torch.float),\n",
    "            'usage': torch.tensor(usage_one_hot, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "        features = {\n",
    "            'image': image,\n",
    "            'masterCategory': torch.tensor(master_category_idx, dtype=torch.float).to(device),\n",
    "            'subCategory': torch.tensor(sub_category_idx, dtype=torch.float).to(device),\n",
    "            'baseColour': torch.tensor(base_colour_idx, dtype=torch.float).to(device),\n",
    "            'year': torch.tensor(year, dtype=torch.float).to(device),\n",
    "            'productDisplayName': product_display_name_embedding.squeeze(0)  # Ensure it is 1D for concatenation\n",
    "        }\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "# Data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets with consistent label structure\n",
    "train_dataset = FashionDataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    root_dir=root_imageset_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = FashionDataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    root_dir=root_imageset_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = FashionDataset(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    root_dir=root_imageset_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"data-loader end..\\n\")\n",
    "\n",
    "# Function to get the backbone model\n",
    "def get_backbone(backbone_name, pretrained=True):\n",
    "    if backbone_name == \"resnet18\":\n",
    "        return models.resnet18(pretrained=pretrained)\n",
    "    elif backbone_name == \"resnet50\":\n",
    "        return models.resnet50(pretrained=pretrained)\n",
    "    elif backbone_name == \"efficientnet_b0\":\n",
    "        return models.efficientnet_b0(pretrained=pretrained)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported backbone: {backbone_name}\")\n",
    "\n",
    "# Define the model\n",
    "class FashionModel(nn.Module):\n",
    "    def __init__(self, num_gender, num_article, num_season, num_usage, num_additional_features, backbone_name=\"resnet18\"):\n",
    "        super(FashionModel, self).__init__()\n",
    "        self.backbone = get_backbone(backbone_name)\n",
    "        # EfficientNet uses `classifier` as the final layer\n",
    "        if hasattr(self.backbone, 'fc'):\n",
    "            num_features = self.backbone.fc.in_features  # ResNet-style models\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        elif hasattr(self.backbone, 'classifier'):\n",
    "            num_features = self.backbone.classifier[-1].in_features  # EfficientNet\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # Combine image features with additional features\n",
    "        self.fc1 = nn.Linear(num_features + num_additional_features, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Define new classification layers using the retrieved num_features\n",
    "        self.gender_classifier = nn.Linear(512, num_gender)\n",
    "        self.article_classifier = nn.Linear(512, num_article)\n",
    "        self.season_classifier = nn.Linear(512, num_season)\n",
    "        self.usage_classifier = nn.Linear(512, num_usage)\n",
    "\n",
    "    def forward(self, x_image, x_features):\n",
    "        image_features = self.backbone(x_image)\n",
    "        combined_features = torch.cat((image_features, x_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        gender_output = self.gender_classifier(x)\n",
    "        article_output = self.article_classifier(x)\n",
    "        season_output = self.season_classifier(x)\n",
    "        usage_output = self.usage_classifier(x)\n",
    "\n",
    "        return gender_output, article_output, season_output, usage_output\n",
    "\n",
    "# Initialize the model and move to GPU\n",
    "num_gender = len(label_encoders['gender'].classes_)\n",
    "num_article = len(label_encoders['articleType'].classes_)\n",
    "num_season = len(label_encoders['season'].classes_)\n",
    "num_usage = len(label_encoders['usage'].classes_)\n",
    "num_additional_features = 4 + 300  # 4 for categorical and year, 300 for Word2Vec embedding\n",
    "\n",
    "backbone_name = \"efficientnet_b0\"  # Change this to switch backbones\n",
    "model = FashionModel(num_gender, num_article, num_season, num_usage, num_additional_features, backbone_name).to(device)\n",
    "\n",
    "# Define cross-entropy class\n",
    "class CE_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CE_Loss, self).__init__()\n",
    "    def forward(self, inputs, targets, size_average=False):\n",
    "        logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        if size_average:\n",
    "            return torch.mean(torch.sum(-targets * logsoftmax(inputs), dim=1))\n",
    "        else:\n",
    "            return torch.sum(torch.sum(-targets * logsoftmax(inputs), dim=1))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = CE_Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation loop\n",
    "best_f1_score = 0.0\n",
    "max_epoch = 0\n",
    "\n",
    "# Calculate validation performance metrics\n",
    "def evaluate_performance(true, pred):\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    precision = precision_score(true, pred, average='weighted')\n",
    "    recall = recall_score(true, pred, average='weighted')\n",
    "    f1 = f1_score(true, pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def save_log(root_log_dir, content):\n",
    "    with open(os.path.join(root_log_dir, 'max_epoch_log.txt'), 'a') as f:\n",
    "        f.write(\"{}\".format(content))\n",
    "\n",
    "print(\"start Training..\\n\")\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for features, labels in train_loader:\n",
    "        images = features['image'].to(device).float()  # Ensure images are FloatTensor\n",
    "        additional_features = torch.cat([\n",
    "            features['masterCategory'].unsqueeze(1),\n",
    "            features['subCategory'].unsqueeze(1),\n",
    "            features['baseColour'].unsqueeze(1),\n",
    "            features['year'].unsqueeze(1),\n",
    "            features['productDisplayName'].to(device)  # Ensure it is on the same device\n",
    "        ], dim=1)\n",
    "\n",
    "        labels = {key: value.to(device) for key, value in labels.items()}  # Move labels to device\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        gender_output, article_output, season_output, usage_output = model(images, additional_features)\n",
    "\n",
    "        # Calculate loss for each task\n",
    "        loss_gender = criterion(gender_output, labels['gender'])\n",
    "        loss_article = criterion(article_output, labels['articleType'])\n",
    "        loss_season = criterion(season_output, labels['season'])\n",
    "        loss_usage = criterion(usage_output, labels['usage'])\n",
    "\n",
    "        # Total loss\n",
    "        loss = loss_gender + loss_article + loss_season + loss_usage\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_gender_true = []\n",
    "    val_gender_pred = []\n",
    "    val_article_true = []\n",
    "    val_article_pred = []\n",
    "    val_season_true = []\n",
    "    val_season_pred = []\n",
    "    val_usage_true = []\n",
    "    val_usage_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            images = features['image'].to(device).float()\n",
    "            additional_features = torch.cat([\n",
    "                features['masterCategory'].unsqueeze(1),\n",
    "                features['subCategory'].unsqueeze(1),\n",
    "                features['baseColour'].unsqueeze(1),\n",
    "                features['year'].unsqueeze(1),\n",
    "                features['productDisplayName'].to(device)  # Ensure it is on the same device\n",
    "            ], dim=1)\n",
    "\n",
    "            labels = {key: value.to(device) for key, value in labels.items()}\n",
    "\n",
    "            gender_output, article_output, season_output, usage_output = model(images, additional_features)\n",
    "\n",
    "            _, predicted_gender = torch.max(gender_output, 1)\n",
    "            _, predicted_article = torch.max(article_output, 1)\n",
    "            _, predicted_season = torch.max(season_output, 1)\n",
    "            _, predicted_usage = torch.max(usage_output, 1)\n",
    "\n",
    "            val_gender_true.extend(torch.argmax(labels['gender'], dim=1).cpu().numpy())\n",
    "            val_gender_pred.extend(predicted_gender.cpu().numpy())\n",
    "            val_article_true.extend(torch.argmax(labels['articleType'], dim=1).cpu().numpy())\n",
    "            val_article_pred.extend(predicted_article.cpu().numpy())\n",
    "            val_season_true.extend(torch.argmax(labels['season'], dim=1).cpu().numpy())\n",
    "            val_season_pred.extend(predicted_season.cpu().numpy())\n",
    "            val_usage_true.extend(torch.argmax(labels['usage'], dim=1).cpu().numpy())\n",
    "            val_usage_pred.extend(predicted_usage.cpu().numpy())\n",
    "\n",
    "    gender_metrics = evaluate_performance(val_gender_true, val_gender_pred)\n",
    "    article_metrics = evaluate_performance(val_article_true, val_article_pred)\n",
    "    season_metrics = evaluate_performance(val_season_true, val_season_pred)\n",
    "    usage_metrics = evaluate_performance(val_usage_true, val_usage_pred)\n",
    "\n",
    "    avg_f1_score = (gender_metrics[3] + article_metrics[3] + season_metrics[3] + usage_metrics[3]) / 4\n",
    "    avg_acc = (gender_metrics[0] + article_metrics[0] + season_metrics[0] + usage_metrics[0]) / 4\n",
    "    \n",
    "    # Save the best model\n",
    "    if avg_f1_score > best_f1_score:\n",
    "        max_epoch = epoch + 1\n",
    "        best_f1_score = avg_f1_score\n",
    "        content = \"epoch(valid):{},{}\\n\".format(max_epoch, best_f1_score)\n",
    "        save_log(root_work_dir, content)\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(root_work_weight_dir, \"train_{}.pth\".format(epoch + 1)))\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Training Loss: {running_loss/len(train_loader):.4f}, '\n",
    "          f'Validation F1 Score: {avg_f1_score:.4f}, '\n",
    "          f'Validation gender F1 Score: {gender_metrics[3]:.4f}, ' \n",
    "          f'Validation article F1 Score: {article_metrics[3]:.4f}, '\n",
    "          f'Validation season F1 Score: {season_metrics[3]:.4f}, '\n",
    "          f'Validation usage_metrics F1 Score: {usage_metrics[3]:.4f}, '\n",
    "          f'Validation Acc Score: {avg_acc:.4f}, '\n",
    "         )\n",
    "\n",
    "\n",
    "print('Training completed\\n')\n",
    "\n",
    "print('Test start..\\n')\n",
    "# Load the saved model\n",
    "model.load_state_dict(torch.load(os.path.join(root_work_weight_dir,\"train_{}.pth\".format(max_epoch))))\n",
    "# Evaluate performance on the test set\n",
    "model.eval()\n",
    "test_gender_true = []\n",
    "test_gender_pred = []\n",
    "test_article_true = []\n",
    "test_article_pred = []\n",
    "test_season_true = []\n",
    "test_season_pred = []\n",
    "test_usage_true = []\n",
    "test_usage_pred = []\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        images = features['image'].to(device).float()\n",
    "        additional_features = torch.cat([\n",
    "            features['masterCategory'].unsqueeze(1),\n",
    "            features['subCategory'].unsqueeze(1),\n",
    "            features['baseColour'].unsqueeze(1),\n",
    "            features['year'].unsqueeze(1),\n",
    "            features['productDisplayName'].to(device)  # Ensure it is on the same device\n",
    "        ], dim=1)\n",
    "\n",
    "        labels = {key: value.to(device) for key, value in labels.items()}\n",
    "\n",
    "        gender_output, article_output, season_output, usage_output = model(images, additional_features)\n",
    "\n",
    "        _, predicted_gender = torch.max(gender_output, 1)\n",
    "        _, predicted_article = torch.max(article_output, 1)\n",
    "        _, predicted_season = torch.max(season_output, 1)\n",
    "        _, predicted_usage = torch.max(usage_output, 1)\n",
    "\n",
    "        test_gender_true.extend(torch.argmax(labels['gender'], dim=1).cpu().numpy())\n",
    "        test_gender_pred.extend(predicted_gender.cpu().numpy())\n",
    "        test_article_true.extend(torch.argmax(labels['articleType'], dim=1).cpu().numpy())\n",
    "        test_article_pred.extend(predicted_article.cpu().numpy())\n",
    "        test_season_true.extend(torch.argmax(labels['season'], dim=1).cpu().numpy())\n",
    "        test_season_pred.extend(predicted_season.cpu().numpy())\n",
    "        test_usage_true.extend(torch.argmax(labels['usage'], dim=1).cpu().numpy())\n",
    "        test_usage_pred.extend(predicted_usage.cpu().numpy())\n",
    "\n",
    "    gender_metrics = evaluate_performance(test_gender_true, test_gender_pred)\n",
    "    article_metrics = evaluate_performance(test_article_true, test_article_pred)\n",
    "    season_metrics = evaluate_performance(test_season_true, test_season_pred)\n",
    "    usage_metrics = evaluate_performance(test_usage_true, test_usage_pred)\n",
    "\n",
    "    avg_f1_score = (gender_metrics[3] + article_metrics[3] + season_metrics[3] + usage_metrics[3]) / 4\n",
    "    avg_acc = (gender_metrics[0] + article_metrics[0] + season_metrics[0] + usage_metrics[0]) / 4\n",
    "    content = \"epoch(test):{},{}\\n\".format(max_epoch, best_f1_score)\n",
    "    save_log(root_work_dir, content)    \n",
    "    print(f'Epoch [{max_epoch}/{num_epochs}], '\n",
    "          f'Test F1 Score: {avg_f1_score:.4f}, '\n",
    "          f'Test gender F1 Score: {gender_metrics[3]:.4f}, ' \n",
    "          f'Test article F1 Score: {article_metrics[3]:.4f}, '\n",
    "          f'Test season F1 Score: {season_metrics[3]:.4f}, '\n",
    "          f'Test usage_metrics F1 Score: {usage_metrics[3]:.4f}, '\n",
    "          f'Test Acc Score: {avg_acc:.4f}, '\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:32:09.066500Z",
     "iopub.status.busy": "2024-08-11T20:32:09.066185Z",
     "iopub.status.idle": "2024-08-11T20:32:23.783237Z",
     "shell.execute_reply": "2024-08-11T20:32:23.782107Z",
     "shell.execute_reply.started": "2024-08-11T20:32:09.066468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dropbox\n",
      "  Downloading dropbox-12.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=2.16.2 in /opt/conda/lib/python3.10/site-packages (from dropbox) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from dropbox) (1.16.0)\n",
      "Collecting stone<3.3.3,>=2 (from dropbox)\n",
      "  Downloading stone-3.3.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.2->dropbox) (2024.7.4)\n",
      "Collecting ply>=3.4 (from stone<3.3.3,>=2->dropbox)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Downloading dropbox-12.0.2-py3-none-any.whl (572 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.1/572.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading stone-3.3.1-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.3/162.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ply, stone, dropbox\n",
      "Successfully installed dropbox-12.0.2 ply-3.11 stone-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T20:32:23.785316Z",
     "iopub.status.busy": "2024-08-11T20:32:23.784945Z",
     "iopub.status.idle": "2024-08-11T20:33:10.555656Z",
     "shell.execute_reply": "2024-08-11T20:33:10.554667Z",
     "shell.execute_reply.started": "2024-08-11T20:32:23.785283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded /kaggle/working/2024-08-12_04_34_34/max_epoch_log.txt to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/max_epoch_log.txt\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_14.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_14.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_17.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_17.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_19.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_19.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_4.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_4.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_7.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_7.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_3.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_3.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_13.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_13.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_20.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_20.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_10.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_10.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_15.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_15.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_8.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_8.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_16.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_16.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_5.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_5.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_18.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_18.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_6.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_6.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_2.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_2.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_9.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_9.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_11.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_11.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_1.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_1.pth\n",
      "Uploaded /kaggle/working/2024-08-12_04_34_34/weights/train_12.pth to /multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal/2024-08-12_04_34_34/weights/train_12.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dropbox\n",
    "\n",
    "def upload_files_to_dropbox(local_directory, dbx_token,target_base_name=None):\n",
    "    # Dropbox에 연결\n",
    "    dbx = dropbox.Dropbox(dbx_token)\n",
    "\n",
    "    # 로컬 디렉토리 이름을 가져옴\n",
    "    if(target_base_name is None):\n",
    "        base_folder_name = os.path.basename(local_directory.rstrip(os.path.sep))\n",
    "    else:\n",
    "        base_folder_name = os.path.basename(local_directory.rstrip(os.path.sep))\n",
    "        base_folder_name = f\"{target_base_name}/{base_folder_name}\"\n",
    "        \n",
    "\n",
    "    # 지정된 로컬 디렉토리의 파일과 디렉토리를 순회\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for file in files:\n",
    "            # 파일의 전체 로컬 경로\n",
    "            local_path = os.path.join(root, file)\n",
    "            \n",
    "            # Dropbox에 업로드할 경로 설정\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            dropbox_path = f\"/{base_folder_name}/{relative_path.replace(os.path.sep, '/')}\"\n",
    "\n",
    "            # 파일 업로드\n",
    "            with open(local_path, \"rb\") as f:\n",
    "                try:\n",
    "                    dbx.files_upload(f.read(), dropbox_path, mode=dropbox.files.WriteMode(\"overwrite\"))\n",
    "                    print(f\"Uploaded {local_path} to {dropbox_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to upload {local_path} to {dropbox_path}: {e}\")\n",
    "\n",
    "# 설정값 입력\n",
    "LOCAL_DIRECTORY = root_work_dir\n",
    "ACCESS_TOKEN = \"\"\n",
    "\n",
    "upload_files_to_dropbox(LOCAL_DIRECTORY, ACCESS_TOKEN,\"multi-modal_hardparam_ce-loss_efficientnetb0_w2v_normal\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 175990,
     "sourceId": 396802,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6763,
     "sourceId": 9801,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
